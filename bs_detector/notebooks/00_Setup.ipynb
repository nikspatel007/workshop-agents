{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 0: Environment Setup & Verification\n",
    "\n",
    "This notebook verifies your environment is correctly configured for the BS Detector workshop.\n",
    "\n",
    "## What We'll Test:\n",
    "1. **Python Environment** - Correct version and packages installed\n",
    "2. **API Configuration** - At least one LLM provider is configured\n",
    "3. **LLM Connectivity** - Can actually call an LLM\n",
    "4. **Package Imports** - All required packages are available\n",
    "5. **File Structure** - Workshop files are in the right place\n",
    "6. **Basic Functionality** - Core components work as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß ENVIRONMENT SETUP VERIFICATION\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üîß ENVIRONMENT SETUP VERIFICATION\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Ô∏è‚É£ PYTHON ENVIRONMENT\n",
      "----------------------------------------\n",
      "Python version: 3.13.5\n",
      "‚úÖ Python version OK (3.9+)\n",
      "\n",
      "Platform: Darwin 24.5.0\n",
      "Machine: arm64\n",
      "\n",
      "Working directory: /Users/nikpatel/Documents/GitHub/workshop-agents/bs_detector/notebooks\n",
      "‚úÖ Running from notebooks directory\n",
      "\n",
      "‚úÖ Virtual environment active: .venv\n"
     ]
    }
   ],
   "source": [
    "print(\"1Ô∏è‚É£ PYTHON ENVIRONMENT\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Python version\n",
    "python_version = sys.version_info\n",
    "print(f\"Python version: {python_version.major}.{python_version.minor}.{python_version.micro}\")\n",
    "if python_version.major == 3 and python_version.minor >= 9:\n",
    "    print(\"‚úÖ Python version OK (3.9+)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Python 3.9+ recommended\")\n",
    "\n",
    "# Platform info\n",
    "print(f\"\\nPlatform: {platform.system()} {platform.release()}\")\n",
    "print(f\"Machine: {platform.machine()}\")\n",
    "\n",
    "# Working directory\n",
    "cwd = Path.cwd()\n",
    "print(f\"\\nWorking directory: {cwd}\")\n",
    "if \"notebooks\" in str(cwd):\n",
    "    print(\"‚úÖ Running from notebooks directory\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Not in notebooks directory - paths might need adjustment\")\n",
    "\n",
    "# Check if we're in a virtual environment\n",
    "venv = os.environ.get('VIRTUAL_ENV')\n",
    "if venv:\n",
    "    print(f\"\\n‚úÖ Virtual environment active: {Path(venv).name}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No virtual environment detected - recommended to use one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Required Packages Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2Ô∏è‚É£ REQUIRED PACKAGES\n",
      "----------------------------------------\n",
      "‚úÖ langchain            - LangChain core\n",
      "‚úÖ langchain_openai     - OpenAI integration\n",
      "‚úÖ langchain_anthropic  - Anthropic integration\n",
      "‚úÖ langchain_aws        - AWS Bedrock integration\n",
      "‚úÖ langgraph            - LangGraph for agents\n",
      "‚úÖ pydantic             - Data validation\n",
      "‚úÖ pydantic_settings    - Settings management\n",
      "‚úÖ pandas               - Data analysis\n",
      "‚úÖ matplotlib           - Plotting\n",
      "‚úÖ jupyter              - Notebook support\n",
      "‚úÖ pytest               - Testing framework\n",
      "‚úÖ dotenv               - Environment variables\n",
      "\n",
      "‚úÖ All required packages installed!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2Ô∏è‚É£ REQUIRED PACKAGES\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Core packages to check\n",
    "packages = {\n",
    "    \"langchain\": \"LangChain core\",\n",
    "    \"langchain_openai\": \"OpenAI integration\",\n",
    "    \"langchain_anthropic\": \"Anthropic integration\",\n",
    "    \"langchain_aws\": \"AWS Bedrock integration\",\n",
    "    \"langgraph\": \"LangGraph for agents\",\n",
    "    \"pydantic\": \"Data validation\",\n",
    "    \"pydantic_settings\": \"Settings management\",\n",
    "    \"pandas\": \"Data analysis\",\n",
    "    \"matplotlib\": \"Plotting\",\n",
    "    \"jupyter\": \"Notebook support\",\n",
    "    \"pytest\": \"Testing framework\",\n",
    "    \"dotenv\": \"Environment variables\"\n",
    "}\n",
    "\n",
    "missing_packages = []\n",
    "for package, description in packages.items():\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úÖ {package:<20} - {description}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package:<20} - {description}\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"   Run: pip install -r ../requirements.txt\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All required packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. API Configuration Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3Ô∏è‚É£ API CONFIGURATION\n",
      "----------------------------------------\n",
      "‚úÖ Loaded .env file\n",
      "‚úÖ OpenAI          - Configured\n",
      "‚úÖ Anthropic       - Configured\n",
      "‚úÖ AWS (Bedrock)   - Configured\n",
      "‚úÖ Azure OpenAI    - Configured\n",
      "\n",
      "‚úÖ Available providers: OpenAI, Anthropic, AWS (Bedrock), Azure OpenAI\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3Ô∏è‚É£ API CONFIGURATION\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Try to load .env file\n",
    "env_path = Path(\"../.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"‚úÖ Loaded .env file\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No .env file found - using system environment variables\")\n",
    "\n",
    "# Check API keys\n",
    "providers = {\n",
    "    \"OpenAI\": \"OPENAI_API_KEY\",\n",
    "    \"Anthropic\": \"ANTHROPIC_API_KEY\", \n",
    "    \"AWS (Bedrock)\": [\"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\"],\n",
    "    \"Azure OpenAI\": [\"AZURE_OPENAI_ENDPOINT\", \"AZURE_OPENAI_API_KEY\"]\n",
    "}\n",
    "\n",
    "configured_providers = []\n",
    "for provider, keys in providers.items():\n",
    "    if isinstance(keys, str):\n",
    "        keys = [keys]\n",
    "    \n",
    "    all_configured = all(os.getenv(key) for key in keys)\n",
    "    if all_configured:\n",
    "        print(f\"‚úÖ {provider:<15} - Configured\")\n",
    "        configured_providers.append(provider)\n",
    "    else:\n",
    "        missing = [k for k in keys if not os.getenv(k)]\n",
    "        print(f\"‚ùå {provider:<15} - Missing: {', '.join(missing)}\")\n",
    "\n",
    "if configured_providers:\n",
    "    print(f\"\\n‚úÖ Available providers: {', '.join(configured_providers)}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå No LLM providers configured!\")\n",
    "    print(\"   1. Copy .env.example to .env\")\n",
    "    print(\"   2. Add your API keys\")\n",
    "    print(\"   3. Restart this notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Workshop File Structure Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4Ô∏è‚É£ FILE STRUCTURE\n",
      "----------------------------------------\n",
      "Directories:\n",
      "‚úÖ ../config                 - Configuration modules\n",
      "‚úÖ ../modules                - BS detector modules\n",
      "‚úÖ ../tests                  - Test files\n",
      "‚ùå ../iterations             - Workshop iterations (NOT FOUND)\n",
      "‚úÖ .                         - Notebooks directory\n",
      "\n",
      "Key files:\n",
      "‚úÖ ../config/llm_factory.py  - LLM factory\n",
      "‚úÖ ../requirements.txt       - Dependencies\n",
      "‚úÖ ./01_Baseline.ipynb       - Baseline notebook\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4Ô∏è‚É£ FILE STRUCTURE\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Expected structure\n",
    "expected_dirs = {\n",
    "    \"../config\": \"Configuration modules\",\n",
    "    \"../modules\": \"BS detector modules\", \n",
    "    \"../tests\": \"Test files\",\n",
    "    \"../iterations\": \"Workshop iterations\",\n",
    "    \".\": \"Notebooks directory\"\n",
    "}\n",
    "\n",
    "expected_files = {\n",
    "    \"../config/llm_factory.py\": \"LLM factory\",\n",
    "    \"../requirements.txt\": \"Dependencies\",\n",
    "    \"./01_Baseline.ipynb\": \"Baseline notebook\"\n",
    "}\n",
    "\n",
    "# Check directories\n",
    "print(\"Directories:\")\n",
    "for dir_path, description in expected_dirs.items():\n",
    "    path = Path(dir_path)\n",
    "    if path.exists() and path.is_dir():\n",
    "        print(f\"‚úÖ {dir_path:<25} - {description}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {dir_path:<25} - {description} (NOT FOUND)\")\n",
    "\n",
    "# Check files\n",
    "print(\"\\nKey files:\")\n",
    "for file_path, description in expected_files.items():\n",
    "    path = Path(file_path)\n",
    "    if path.exists():\n",
    "        print(f\"‚úÖ {file_path:<25} - {description}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file_path:<25} - {description} (NOT FOUND)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LLM Factory Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5Ô∏è‚É£ LLM FACTORY TEST\n",
      "----------------------------------------\n",
      "‚úÖ LLMFactory imported successfully\n",
      "\n",
      "Attempting to create LLM...\n",
      "‚úÖ Created LLM: ChatOpenAI\n",
      "   Model: gpt-4.1-mini\n",
      "\n",
      "Testing LLM response...\n",
      "‚úÖ LLM Response: The Boeing 747 is a large, long-range wide-body commercial airliner and cargo aircraft, often referr...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5Ô∏è‚É£ LLM FACTORY TEST\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path(\"..\").resolve()))\n",
    "\n",
    "try:\n",
    "    from config.llm_factory import LLMFactory\n",
    "    print(\"‚úÖ LLMFactory imported successfully\")\n",
    "    \n",
    "    # Try to create an LLM\n",
    "    print(\"\\nAttempting to create LLM...\")\n",
    "    llm = LLMFactory.create_llm()\n",
    "    print(f\"‚úÖ Created LLM: {llm.__class__.__name__}\")\n",
    "    \n",
    "    # Get the provider info\n",
    "    if hasattr(llm, \"model_name\"):\n",
    "        print(f\"   Model: {llm.model_name}\")\n",
    "    elif hasattr(llm, \"model\"):\n",
    "        print(f\"   Model: {llm.model}\")\n",
    "    \n",
    "    # Test with a simple prompt\n",
    "    print(\"\\nTesting LLM response...\")\n",
    "    try:\n",
    "        response = llm.invoke(\"Complete this: The Boeing 747 is a\")\n",
    "        content = response.content if hasattr(response, 'content') else str(response)\n",
    "        print(f\"‚úÖ LLM Response: {content[:100]}...\")\n",
    "        \n",
    "        # Store for later use\n",
    "        working_llm = llm\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLM call failed: {str(e)[:100]}...\")\n",
    "        working_llm = None\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Failed to import LLMFactory: {e}\")\n",
    "    working_llm = None\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create LLM: {str(e)[:200]}...\")\n",
    "    working_llm = None\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check your API keys are set correctly\")\n",
    "    print(\"2. Ensure you have network connectivity\")\n",
    "    print(\"3. Verify your API key has proper permissions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basic Functionality Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6Ô∏è‚É£ BASIC FUNCTIONALITY TEST\n",
      "----------------------------------------\n",
      "‚úÖ Baseline module imported\n",
      "‚úÖ Pydantic model works\n",
      "\n",
      "Testing BS detection...\n",
      "‚úÖ 'The Boeing 747 has four engine...' ‚Üí LEGITIMATE\n",
      "‚úÖ 'Commercial planes can fly to t...' ‚Üí BS\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n6Ô∏è‚É£ BASIC FUNCTIONALITY TEST\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if working_llm:\n",
    "    # Test baseline module if available\n",
    "    try:\n",
    "        from modules.m1_baseline import BSDetectorOutput, check_claim\n",
    "        print(\"‚úÖ Baseline module imported\")\n",
    "        \n",
    "        # Test Pydantic model\n",
    "        test_output = BSDetectorOutput(\n",
    "            verdict=\"BS\",\n",
    "            confidence=95,\n",
    "            reasoning=\"Test reasoning\"\n",
    "        )\n",
    "        print(\"‚úÖ Pydantic model works\")\n",
    "        \n",
    "        # Test actual BS detection\n",
    "        print(\"\\nTesting BS detection...\")\n",
    "        test_claims = [\n",
    "            (\"The Boeing 747 has four engines\", \"LEGITIMATE\"),\n",
    "            (\"Commercial planes can fly to the moon\", \"BS\")\n",
    "        ]\n",
    "        \n",
    "        for claim, expected in test_claims:\n",
    "            result = check_claim(claim, working_llm)\n",
    "            status = \"‚úÖ\" if result['verdict'] == expected else \"‚ö†Ô∏è\"\n",
    "            print(f\"{status} '{claim[:30]}...' ‚Üí {result['verdict']}\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è  Baseline module not yet implemented\")\n",
    "        print(\"   This is expected if you haven't completed Iteration 1\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing baseline: {str(e)[:100]}...\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping functionality test (no working LLM)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline Module Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7Ô∏è‚É£ PERFORMANCE CHECK\n",
      "----------------------------------------\n",
      "Testing LLM response time...\n",
      "‚úÖ LLM response time: 2.02s\n",
      "   Good. Under 5 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n7Ô∏è‚É£ PERFORMANCE CHECK\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if working_llm:\n",
    "    import time\n",
    "    \n",
    "    # Test LLM response time\n",
    "    print(\"Testing LLM response time...\")\n",
    "    start = time.time()\n",
    "    try:\n",
    "        response = working_llm.invoke(\"Is the sky blue?\")\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"‚úÖ LLM response time: {elapsed:.2f}s\")\n",
    "        if elapsed < 2.0:\n",
    "            print(\"   Excellent! Under 2 second target\")\n",
    "        elif elapsed < 5.0:\n",
    "            print(\"   Good. Under 5 seconds\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  Slow response. Consider a faster model\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Performance test failed: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping performance test (no working LLM)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìã SETUP SUMMARY\n",
      "============================================================\n",
      "‚úÖ Python 3.9+\n",
      "‚úÖ Virtual environment\n",
      "‚úÖ All packages installed\n",
      "‚úÖ API keys configured\n",
      "‚úÖ LLM connection works\n",
      "‚úÖ File structure correct\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "üéâ EXCELLENT! Your environment is fully configured!\n",
      "\n",
      "You're ready to:\n",
      "1. Open 01_Baseline.ipynb to start building\n",
      "2. Follow along with the workshop\n",
      "3. Build your BS detector!\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã SETUP SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Collect results\n",
    "checks = {\n",
    "    \"Python 3.9+\": python_version.major == 3 and python_version.minor >= 9,\n",
    "    \"Virtual environment\": bool(venv),\n",
    "    \"All packages installed\": len(missing_packages) == 0,\n",
    "    \"API keys configured\": len(configured_providers) > 0,\n",
    "    \"LLM connection works\": working_llm is not None,\n",
    "    \"File structure correct\": Path(\"../config/llm_factory.py\").exists()\n",
    "}\n",
    "\n",
    "# Display summary\n",
    "all_good = True\n",
    "for check, passed in checks.items():\n",
    "    status = \"‚úÖ\" if passed else \"‚ùå\"\n",
    "    print(f\"{status} {check}\")\n",
    "    if not passed:\n",
    "        all_good = False\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\nüéâ EXCELLENT! Your environment is fully configured!\")\n",
    "    print(\"\\nYou're ready to:\")\n",
    "    print(\"1. Open 01_Baseline.ipynb to start building\")\n",
    "    print(\"2. Follow along with the workshop\")\n",
    "    print(\"3. Build your BS detector!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Some setup items need attention:\")\n",
    "    print(\"\\n1. If packages are missing:\")\n",
    "    print(\"   pip install -r ../requirements.txt\")\n",
    "    print(\"\\n2. If API keys are missing:\")\n",
    "    print(\"   - Copy .env.example to .env\")\n",
    "    print(\"   - Add your API keys\")\n",
    "    print(\"   - Restart this notebook\")\n",
    "    print(\"\\n3. If LLM connection fails:\")\n",
    "    print(\"   - Check your API key is valid\")\n",
    "    print(\"   - Ensure you have internet access\")\n",
    "    print(\"   - Try a different provider\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
