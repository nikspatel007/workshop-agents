{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2: Introduction to LangGraph\n",
    "\n",
    "In this iteration, we'll convert our baseline BS detector to use LangGraph, adding retry logic and learning the core concepts.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand LangGraph's 5 core concepts: State, Node, Edge, Routing, Graph\n",
    "- Convert existing code to graph-based architecture\n",
    "- Add retry logic using graph cycles\n",
    "- Learn two execution patterns: single run and chat loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Overview\n",
    "\n",
    "Let's visualize what we're building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\"></script>\n",
       "<script>\n",
       "mermaid.initialize({ \n",
       "    startOnLoad: true,\n",
       "    theme: 'default',\n",
       "    themeVariables: {\n",
       "        fontSize: '16px'\n",
       "    }\n",
       "});\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script src=\"https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js\"></script>\n",
    "<script>\n",
    "mermaid.initialize({ \n",
    "    startOnLoad: true,\n",
    "    theme: 'default',\n",
    "    themeVariables: {\n",
    "        fontSize: '16px'\n",
    "    }\n",
    "});\n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/CmdyYXBoIFRECiAgICBTdGFydChbU3RhcnRdKSAtLT4gRGV0ZWN0W0RldGVjdCBCUyBOb2RlXQogICAgRGV0ZWN0IC0tPiBSb3V0ZXJ7Um91dGUgRGVjaXNpb259CiAgICBSb3V0ZXIgLS0+fFN1Y2Nlc3N8IEZvcm1hdFtGb3JtYXQgT3V0cHV0XQogICAgUm91dGVyIC0tPnxSZXRyeXwgUmV0cnlbUmV0cnkgTm9kZV0KICAgIFJvdXRlciAtLT58TWF4IFJldHJpZXN8IEZvcm1hdAogICAgUmV0cnkgLS0+IERldGVjdAogICAgRm9ybWF0IC0tPiBFbmQoW0VuZF0pCgogICAgc3R5bGUgU3RhcnQgZmlsbDojOTBFRTkwCiAgICBzdHlsZSBFbmQgZmlsbDojRkZCNkMxCiAgICBzdHlsZSBEZXRlY3QgZmlsbDojODdDRUVCCiAgICBzdHlsZSBSZXRyeSBmaWxsOiNGRkU0QjUK?type=png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Define the mermaid diagram\n",
    "mermaid_graph = \"\"\"\n",
    "graph TD\n",
    "    Start([Start]) --> Detect[Detect BS Node]\n",
    "    Detect --> Router{Route Decision}\n",
    "    Router -->|Success| Format[Format Output]\n",
    "    Router -->|Retry| Retry[Retry Node]\n",
    "    Router -->|Max Retries| Format\n",
    "    Retry --> Detect\n",
    "    Format --> End([End])\n",
    "\n",
    "    style Start fill:#90EE90\n",
    "    style End fill:#FFB6C1\n",
    "    style Detect fill:#87CEEB\n",
    "    style Retry fill:#FFE4B5\n",
    "\"\"\"\n",
    "\n",
    "# Use mermaid.ink API to render the diagram\n",
    "def render_mermaid_diagram(graph_def):\n",
    "    \"\"\"Render mermaid diagram using mermaid.ink API\"\"\"\n",
    "    graph_bytes = graph_def.encode(\"utf-8\")\n",
    "    base64_string = base64.b64encode(graph_bytes).decode(\"ascii\")\n",
    "    image_url = f\"https://mermaid.ink/img/{base64_string}?type=png\"\n",
    "    \n",
    "    # Display the image\n",
    "    return Image(url=image_url)\n",
    "\n",
    "# Display the diagram\n",
    "display(render_mermaid_diagram(mermaid_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LLM: ChatOpenAI\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our baseline detector from Iteration 1\n",
    "from modules.m1_baseline import BSDetectorOutput, check_claim\n",
    "from modules.m2_langgraph import (\n",
    "    BSDetectorState,\n",
    "    create_bs_detector_graph,\n",
    "    check_claim_with_graph,\n",
    "    visualize_graph\n",
    ")\n",
    "from config.llm_factory import LLMFactory\n",
    "\n",
    "# Create LLM instance\n",
    "llm = LLMFactory.create_llm()\n",
    "print(f\"Using LLM: {llm.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding LangGraph Concepts\n",
    "\n",
    "### Concept 1: State\n",
    "State is the shared data between nodes. We use Pydantic BaseModel for validation and type safety!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example state: {'claim': 'The Boeing 747 can fly backwards', 'retry_count': 0, 'max_retries': 3, 'verdict': None, 'confidence': None, 'reasoning': None, 'error': None, 'result': None}\n",
      "State type: <class '__main__.BSDetectorState'>\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Let's look at our state definition using Pydantic\n",
    "class BSDetectorState(BaseModel):\n",
    "    \"\"\"Everything our graph needs to remember - with validation!\"\"\"\n",
    "    # Input\n",
    "    claim: str\n",
    "    \n",
    "    # Processing control\n",
    "    retry_count: int = 0\n",
    "    max_retries: int = 3\n",
    "    \n",
    "    # Output\n",
    "    verdict: Optional[str] = None\n",
    "    confidence: Optional[int] = None\n",
    "    reasoning: Optional[str] = None\n",
    "    error: Optional[str] = None\n",
    "    result: Optional[dict] = None\n",
    "\n",
    "# Example state - now with validation!\n",
    "example_state = BSDetectorState(\n",
    "    claim=\"The Boeing 747 can fly backwards\",\n",
    "    retry_count=0,\n",
    "    max_retries=3\n",
    ")\n",
    "print(\"Example state:\", example_state.model_dump())\n",
    "print(\"State type:\", type(example_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept 2: Node\n",
    "A node is just a function that takes state and returns updates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node returns updates: {'verdict': 'BS', 'confidence': 95}\n",
      "Original state is unchanged: None\n"
     ]
    }
   ],
   "source": [
    "def simple_node(state: BSDetectorState) -> dict:\n",
    "    \"\"\"A node processes state and returns updates\"\"\"\n",
    "    claim = state.claim  # Access fields as attributes\n",
    "    \n",
    "    # Do some processing\n",
    "    if \"backwards\" in claim.lower():\n",
    "        verdict = \"BS\"\n",
    "    else:\n",
    "        verdict = \"LEGITIMATE\"\n",
    "    \n",
    "    # Return ONLY the fields to update\n",
    "    return {\n",
    "        \"verdict\": verdict,\n",
    "        \"confidence\": 95\n",
    "    }\n",
    "\n",
    "# Test the node\n",
    "updates = simple_node(example_state)\n",
    "print(\"Node returns updates:\", updates)\n",
    "print(\"Original state is unchanged:\", example_state.verdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concept 3: Routing\n",
    "Routing functions decide which path to take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verdict: BS, Retries: 0/3 → Route: success\n",
      "Verdict: None, Retries: 1/3 → Route: retry\n",
      "Verdict: None, Retries: 3/3 → Route: give_up\n"
     ]
    }
   ],
   "source": [
    "def routing_function(state: BSDetectorState) -> str:\n",
    "    \"\"\"Decide next step based on state\"\"\"\n",
    "    if state.verdict:\n",
    "        return \"success\"\n",
    "    elif state.retry_count < state.max_retries:\n",
    "        return \"retry\"\n",
    "    else:\n",
    "        return \"give_up\"\n",
    "\n",
    "# Test routing with different states\n",
    "test_states = [\n",
    "    BSDetectorState(claim=\"test\", verdict=\"BS\", retry_count=0, max_retries=3),\n",
    "    BSDetectorState(claim=\"test\", verdict=None, retry_count=1, max_retries=3),\n",
    "    BSDetectorState(claim=\"test\", verdict=None, retry_count=3, max_retries=3)\n",
    "]\n",
    "\n",
    "for state in test_states:\n",
    "    route = routing_function(state)\n",
    "    print(f\"Verdict: {state.verdict}, Retries: {state.retry_count}/{state.max_retries} → Route: {route}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a Simple Graph Step-by-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graph compiled successfully!\n",
      "\n",
      "📊 Here's what we built:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/LS0tCmNvbmZpZzoKICBmbG93Y2hhcnQ6CiAgICBjdXJ2ZTogbGluZWFyCi0tLQpncmFwaCBURDsKCV9fc3RhcnRfXyhbPHA+X19zdGFydF9fPC9wPl0pOjo6Zmlyc3QKCWRldGVjdChkZXRlY3QpCglyZXRyeShyZXRyeSkKCV9fZW5kX18oWzxwPl9fZW5kX188L3A+XSk6OjpsYXN0CglfX3N0YXJ0X18gLS0+IGRldGVjdDsKCWRldGVjdCAtLiAmbmJzcDtkb25lJm5ic3A7IC4tPiBfX2VuZF9fOwoJZGV0ZWN0IC0uLT4gcmV0cnk7CglyZXRyeSAtLT4gZGV0ZWN0OwoJY2xhc3NEZWYgZGVmYXVsdCBmaWxsOiNmMmYwZmYsbGluZS1oZWlnaHQ6MS4yCgljbGFzc0RlZiBmaXJzdCBmaWxsLW9wYWNpdHk6MAoJY2xhc3NEZWYgbGFzdCBmaWxsOiNiZmI2ZmMK?type=png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Step 1: Create a graph with our Pydantic state\n",
    "graph = StateGraph(BSDetectorState)\n",
    "\n",
    "# Step 2: Add nodes (we'll use simplified versions)\n",
    "def detect_node(state: BSDetectorState) -> dict:\n",
    "    print(f\"🔍 Detecting BS for: {state.claim[:30]}...\")\n",
    "    # Simulate detection\n",
    "    return {\"verdict\": \"BS\", \"confidence\": 90}\n",
    "\n",
    "def retry_node(state: BSDetectorState) -> dict:\n",
    "    print(f\"🔄 Retry {state.retry_count + 1}\")\n",
    "    return {\"retry_count\": state.retry_count + 1}\n",
    "\n",
    "graph.add_node(\"detect\", detect_node)\n",
    "graph.add_node(\"retry\", retry_node)\n",
    "\n",
    "# Step 3: Set entry point\n",
    "graph.set_entry_point(\"detect\")\n",
    "\n",
    "# Step 4: Add routing\n",
    "def simple_router(state: BSDetectorState) -> str:\n",
    "    if state.verdict:\n",
    "        return \"done\"\n",
    "    return \"retry\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"detect\",\n",
    "    simple_router,\n",
    "    {\"done\": END, \"retry\": \"retry\"}\n",
    ")\n",
    "\n",
    "# Step 5: Connect retry back to detect\n",
    "graph.add_edge(\"retry\", \"detect\")\n",
    "\n",
    "# Step 6: Compile\n",
    "simple_app = graph.compile()\n",
    "\n",
    "print(\"✅ Graph compiled successfully!\")\n",
    "\n",
    "# Step 7: Visualize the graph we just built\n",
    "print(\"\\n📊 Here's what we built:\")\n",
    "mermaid_code = simple_app.get_graph().draw_mermaid()\n",
    "display(render_mermaid_diagram(mermaid_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare Baseline vs LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 🔹 Baseline Version (no retry)\nFirst, let's see how our original baseline detector handles the claim:",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### 🔹 LangGraph Version (with retry)\nNow let's see how the LangGraph version handles the same claim with retry logic:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "test_claim = \"The Airbus A380 can do barrel rolls\"\n\n# Baseline Version (no retry)\nbaseline_result = check_claim(test_claim, llm)\nprint(f\"Verdict: {baseline_result['verdict']}\")\nprint(f\"Confidence: {baseline_result['confidence']}%\")\nprint(f\"Reasoning: {baseline_result['reasoning']}\")\n\nprint()  # Empty line for spacing\n\n# LangGraph Version (with retry)\ngraph_result = check_claim_with_graph(test_claim, max_retries=3)\nprint(f\"Verdict: {graph_result['verdict']}\")\nprint(f\"Confidence: {graph_result['confidence']}%\")\nprint(f\"Reasoning: {graph_result['reasoning']}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Execution Pattern 1: Single Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Claim: The Boeing 747 has four engines\n",
      "→ LEGITIMATE\n",
      "\n",
      "Claim: Helicopters fly using jet propulsion\n",
      "→ BS\n",
      "\n",
      "Claim: The Concorde could break the sound barrier\n",
      "→ LEGITIMATE\n"
     ]
    }
   ],
   "source": [
    "def single_run_demo():\n",
    "    \"\"\"Execute the graph once\"\"\"\n",
    "    # Create the graph\n",
    "    app = create_bs_detector_graph()\n",
    "    \n",
    "    # Test claims\n",
    "    claims = [\n",
    "        \"The Boeing 747 has four engines\",\n",
    "        \"Helicopters fly using jet propulsion\",\n",
    "        \"The Concorde could break the sound barrier\"\n",
    "    ]\n",
    "    \n",
    "    for claim in claims:\n",
    "        print(f\"\\nClaim: {claim}\")\n",
    "        \n",
    "        # Initialize state with Pydantic model\n",
    "        state = BSDetectorState(\n",
    "            claim=claim,\n",
    "            retry_count=0,\n",
    "            max_retries=2\n",
    "        )\n",
    "        \n",
    "        # Run the graph\n",
    "        result = app.invoke(state)\n",
    "        \n",
    "        # Extract verdict from the result dictionary\n",
    "        if result.get(\"result\"):\n",
    "            print(f\"→ {result['result']['verdict']}\")\n",
    "\n",
    "single_run_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execution Pattern 2: Interactive Chat\n",
    "\n",
    "Now let's create a real interactive chat where you can keep entering claims until you're ready to exit. This shows how the graph can be reused for multiple queries in a session."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### 🤖 BS Detector Chat - Interactive Mode\n\nType aviation claims to check them. You can:\n- Enter any aviation-related claim to verify\n- Type 'quit', 'exit', or 'q' to stop the chat",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Note**: When you run the cell below, it will wait for your input. Type an aviation claim and press Enter. Keep entering claims until you type 'quit' to exit."
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 BS Detector Chat - Interactive Mode\n",
      "========================================\n",
      "Type aviation claims to check them.\n",
      "Type 'quit', 'exit', or 'q' to stop.\n",
      "========================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 Enter claim:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👋 Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Interactive Chat Interface\n",
    "print(\"🤖 BS Detector Chat - Interactive Mode\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Type aviation claims to check them.\")\n",
    "print(\"Type 'quit', 'exit', or 'q' to stop.\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create the graph once\n",
    "app = create_bs_detector_graph()\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    # Get user input\n",
    "    claim = input(\"\\n💬 Enter claim: \").strip()\n",
    "    \n",
    "    # Check for exit\n",
    "    if claim.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"\\n👋 Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    # Skip empty input\n",
    "    if not claim:\n",
    "        continue\n",
    "    \n",
    "    print(\"\\n🔍 Analyzing...\")\n",
    "    \n",
    "    # Process with graph\n",
    "    state = app.invoke(BSDetectorState(\n",
    "        claim=claim,\n",
    "        retry_count=0,\n",
    "        max_retries=3\n",
    "    ))\n",
    "    \n",
    "    # Show result\n",
    "    result = state.get(\"result\") or {}\n",
    "    \n",
    "    if result.get(\"verdict\") and result[\"verdict\"] != \"ERROR\":\n",
    "        print(f\"\\n📊 Verdict: {result['verdict']}\")\n",
    "        print(f\"🎯 Confidence: {result['confidence']}%\")\n",
    "        print(f\"💭 Reasoning: {result['reasoning']}\")\n",
    "    else:\n",
    "        print(f\"\\n❌ Error: {result.get('error', 'Unknown error')}\")\n",
    "    \n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the complete BS Detector graph with all nodes:\n",
      "BS Detector Graph Structure:\n",
      "==================================================\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tdetect(detect)\n",
      "\tretry(retry)\n",
      "\tformat_output(format_output)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> detect;\n",
      "\tdetect -. &nbsp;error&nbsp; .-> format_output;\n",
      "\tdetect -.-> retry;\n",
      "\tretry --> detect;\n",
      "\tformat_output --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n",
      "\n",
      "Graph Flow:\n",
      "1. Start → Detect BS\n",
      "2. If success → Format Output → End\n",
      "3. If error & retries left → Retry → Detect BS\n",
      "4. If max retries → Format Output → End\n",
      "(Visual display not available in this environment)\n"
     ]
    }
   ],
   "source": [
    "# Show the actual graph structure\n",
    "print(\"Here's the complete BS Detector graph with all nodes:\")\n",
    "graph_image = visualize_graph()\n",
    "if graph_image:\n",
    "    display(graph_image)\n",
    "else:\n",
    "    print(\"(Visual display not available in this environment)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercise: Add a Logging Node\n",
    "\n",
    "Let's practice by adding a new node to our graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 State Log:\n",
      "  Claim: Airplanes can teleport between airports...\n",
      "  Verdict: BS\n",
      "  Retries: 0\n",
      "\n",
      "✅ Graph with logging executed successfully!\n",
      "Final verdict: BS\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "import json\n",
    "\n",
    "# Create a new graph with logging\n",
    "def create_graph_with_logging():\n",
    "    graph = StateGraph(BSDetectorState)\n",
    "    \n",
    "    # Reuse our existing nodes\n",
    "    from modules.m2_langgraph import (\n",
    "        detect_bs_node, \n",
    "        retry_node, \n",
    "        format_output_node,\n",
    "        route_after_detection\n",
    "    )\n",
    "    \n",
    "    # ADD YOUR LOGGING NODE HERE\n",
    "    def log_node(state: BSDetectorState) -> dict:\n",
    "        \"\"\"Log the state for debugging\"\"\"\n",
    "        print(\"\\n📊 State Log:\")\n",
    "        print(f\"  Claim: {state.claim[:50]}...\")\n",
    "        print(f\"  Verdict: {state.verdict or 'None'}\")\n",
    "        print(f\"  Retries: {state.retry_count}\")\n",
    "        return {}  # No state updates\n",
    "    \n",
    "    # Build the graph\n",
    "    graph.add_node(\"detect\", detect_bs_node)\n",
    "    graph.add_node(\"retry\", retry_node)\n",
    "    graph.add_node(\"log\", log_node)  # New!\n",
    "    graph.add_node(\"format\", format_output_node)\n",
    "    \n",
    "    # Entry point\n",
    "    graph.set_entry_point(\"detect\")\n",
    "    \n",
    "    # Routing\n",
    "    graph.add_conditional_edges(\n",
    "        \"detect\",\n",
    "        route_after_detection,\n",
    "        {\n",
    "            \"success\": \"log\",  # Go to log first\n",
    "            \"retry\": \"retry\",\n",
    "            \"error\": \"log\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Connect the rest\n",
    "    graph.add_edge(\"retry\", \"detect\")\n",
    "    graph.add_edge(\"log\", \"format\")  # Log then format\n",
    "    graph.add_edge(\"format\", END)\n",
    "    \n",
    "    return graph.compile()\n",
    "\n",
    "# Test the enhanced graph\n",
    "enhanced_app = create_graph_with_logging()\n",
    "result = enhanced_app.invoke(BSDetectorState(\n",
    "    claim=\"Airplanes can teleport between airports\",\n",
    "    retry_count=0,\n",
    "    max_retries=1\n",
    "))\n",
    "\n",
    "print(\"\\n✅ Graph with logging executed successfully!\")\n",
    "\n",
    "# Show the final result\n",
    "if result.get(\"result\"):\n",
    "    print(f\"Final verdict: {result['result']['verdict']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **State** = Shared memory (Pydantic BaseModel for validation)\n",
    "2. **Node** = Function that processes state\n",
    "3. **Edge** = Connection between nodes\n",
    "4. **Routing** = Conditional flow control\n",
    "5. **Graph** = Complete system\n",
    "\n",
    "### Benefits of LangGraph:\n",
    "- ✅ Separation of concerns (each node has one job)\n",
    "- ✅ Easy to add features (just add nodes)\n",
    "- ✅ Built-in retry logic\n",
    "- ✅ Visual representation of flow\n",
    "- ✅ Testable components\n",
    "- ✅ Type safety with Pydantic models\n",
    "\n",
    "### Next Steps:\n",
    "- Try adding more nodes (validation, caching, etc.)\n",
    "- Experiment with parallel processing\n",
    "- Build more complex routing logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Challenge: Modify the Graph\n",
    "\n",
    "Can you add a confidence adjustment node that:\n",
    "- Reduces confidence by 10% for each retry\n",
    "- Runs after detection but before formatting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here!\n",
    "def confidence_adjustment_node(state: BSDetectorState) -> dict:\n",
    "    \"\"\"Adjust confidence based on retries\"\"\"\n",
    "    if state.confidence and state.retry_count > 0:\n",
    "        # Reduce confidence by 10% for each retry\n",
    "        adjusted_confidence = max(0, state.confidence - (10 * state.retry_count))\n",
    "        return {\"confidence\": adjusted_confidence}\n",
    "    return {}  # No adjustment needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}